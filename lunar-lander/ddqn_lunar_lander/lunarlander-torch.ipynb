{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eafcc0-601b-4609-bed4-567e4653abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184d259-bfe0-4ad8-a43e-8bce502059c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:22:21.755198Z",
     "iopub.status.busy": "2023-02-07T21:22:21.755051Z",
     "iopub.status.idle": "2023-02-07T21:22:23.585329Z",
     "shell.execute_reply": "2023-02-07T21:22:23.584743Z",
     "shell.execute_reply.started": "2023-02-07T21:22:21.755181Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json # for dumping debug data\n",
    "import time # for benchmarking\n",
    "import numpy as np\n",
    "from ddqn_torch import DoubleQAgent\n",
    "\n",
    "LEARN_EVERY = 4\n",
    "def train_agent(n_episodes=2000, load_model=None, best=0, lr = 0.0001, epsilon = 1.0, epsilon_end = 0.05):\n",
    "    print(\"Training a DDQN agent on {} episodes. Pretrained model = {}\".format(n_episodes,load_model))\n",
    "    env = gym.make(\n",
    "            \"LunarLander-v2\",\n",
    "            continuous = False,\n",
    "            gravity = -10.0,\n",
    "            enable_wind = False,\n",
    "            wind_power = 15.0,\n",
    "            turbulence_power = 1.5,\n",
    "        )\n",
    "    agent = DoubleQAgent(gamma=0.95, epsilon=epsilon, epsilon_dec=0.995, lr=lr, mem_size=200000, batch_size=256, epsilon_end=epsilon_end)\n",
    "    if load_model:\n",
    "        agent.load_saved_model(\"models/\"+load_model)\n",
    "        \n",
    "    start_states = []\n",
    "    scores = []\n",
    "    eps_history = []\n",
    "    start = time.time()\n",
    "    best_avg = best\n",
    "    for i in range(n_episodes):\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        score = 0\n",
    "        state = env.reset()[0]\n",
    "        start_states.append(state)\n",
    "        steps = 0\n",
    "        while not (terminated or truncated):\n",
    "            action = agent.choose_action(state)\n",
    "            new_state, reward, terminated, truncated, info = env.step(action)\n",
    "            agent.save(state, action, reward, new_state, terminated)\n",
    "            state = new_state\n",
    "            if steps > 0 and steps % LEARN_EVERY == 0:\n",
    "                agent.learn()\n",
    "            steps += 1\n",
    "            score += reward\n",
    "            \n",
    "        eps_history.append(agent.epsilon)\n",
    "        scores.append(score)\n",
    "        avg_score = np.mean(scores[max(0, i-100):])\n",
    "\n",
    "        if (i+1) % 10 == 0 and i > 0:\n",
    "            # Report expected time to finish the training\n",
    "            print('Episode {} in {:.2f} min. Expected total time for {} episodes: {:.0f} min. [{:.2f}/{:.2f}]'.format((i+1), \n",
    "                                                                                                                      (time.time() - start)/60, \n",
    "\n",
    "        if avg_score > best_avg and i > 100:\n",
    "            best_avg = avg_score\n",
    "            print(\">>> NEW BEST AVERAGE:\",best_avg)\n",
    "            agent.save_model(f'models/ddqn_torch_model_{round(best_avg,2)}.h5')\n",
    "            \n",
    "        # if (i+1) % 100 == 0 and i > 0:\n",
    "            # Save the model every N-th step just in case\n",
    "            # \n",
    "            # with open(\"ddqn_torch_dqn_scores_{}.json\".format(int(time.time())), \"w\") as fp:\n",
    "            #     json.dump(scores, fp)\n",
    "            # with open(\"ddqn_torch_eps_history_{}.json\".format(int(time.time())), \"w\") as fp:\n",
    "            #     json.dump(eps_history, fp)\n",
    "                \n",
    "    return agent, scores, start_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "611f905c-9a67-4de9-a351-be3003b9f26b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:22:23.587161Z",
     "iopub.status.busy": "2023-02-07T21:22:23.586690Z",
     "iopub.status.idle": "2023-02-07T21:22:23.589493Z",
     "shell.execute_reply": "2023-02-07T21:22:23.589027Z",
     "shell.execute_reply.started": "2023-02-07T21:22:23.587140Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a DDQN agent on 10000 episodes. Pretrained model = None\n",
      "Episode 10 in 0.03 min. Expected total time for 10000 episodes: 31 min. [-411.73/-318.19]\n",
      "Episode 20 in 0.23 min. Expected total time for 10000 episodes: 119 min. [-233.95/-267.18]\n",
      "Episode 30 in 0.48 min. Expected total time for 10000 episodes: 166 min. [-179.81/-239.93]\n",
      "Episode 40 in 0.66 min. Expected total time for 10000 episodes: 168 min. [-167.57/-222.65]\n",
      "Episode 50 in 0.96 min. Expected total time for 10000 episodes: 196 min. [-105.13/-199.55]\n",
      "Episode 60 in 1.26 min. Expected total time for 10000 episodes: 214 min. [-167.13/-195.13]\n",
      "Episode 70 in 1.65 min. Expected total time for 10000 episodes: 238 min. [-154.70/-183.97]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb Cell 3\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Uncomment to train\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m agent, scores, start_states \u001b[39m=\u001b[39m train_agent(n_episodes\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m, lr \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m, epsilon \u001b[39m=\u001b[39;49m \u001b[39m0.005\u001b[39;49m, epsilon_end \u001b[39m=\u001b[39;49m \u001b[39m0.005\u001b[39;49m)\n",
      "\u001b[1;32m/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb Cell 3\u001b[0m line \u001b[0;36mtrain_agent\u001b[0;34m(n_episodes, load_model, best, lr, epsilon, epsilon_end)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m state \u001b[39m=\u001b[39m new_state\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mif\u001b[39;00m steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m steps \u001b[39m%\u001b[39m LEARN_EVERY \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     agent\u001b[39m.\u001b[39;49mlearn()\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n",
      "File \u001b[0;32m/workspace/lunar-lander-ddqn/ddqn_torch.py:125\u001b[0m, in \u001b[0;36mAgent.DoubleQAgent.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m q_next \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_func_target(new_states)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m    124\u001b[0m q_updated \u001b[39m=\u001b[39m rewards \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m q_next \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m terminals)\n\u001b[0;32m--> 125\u001b[0m q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_func(states)\u001b[39m.\u001b[39mgather(\u001b[39m1\u001b[39m, actions)\n\u001b[1;32m    127\u001b[0m \u001b[39m# 3. Update the main NN\u001b[39;00m\n\u001b[1;32m    128\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(q, q_updated)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/lunar-lander-ddqn/ddqn_torch.py:48\u001b[0m, in \u001b[0;36mQNN.forward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[0;32m---> 48\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(state)\n\u001b[1;32m     49\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     50\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Uncomment to train\n",
    "import matplotlib.pyplot as plt\n",
    "agent, scores, start_states = train_agent(n_episodes=10000, lr = 0.001, epsilon = 0.005, epsilon_end = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb Cell 4\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m n_latest \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39marray(start_states)[:,:\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39marray(np\u001b[39m.\u001b[39marray(start_states)[:,:\u001b[39m2\u001b[39m][\u001b[39m-\u001b[39mn_latest:])\u001b[39m.\u001b[39mT, c\u001b[39m=\u001b[39mscores[\u001b[39m-\u001b[39mn_latest:], cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRdYlGn\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mcolorbar(label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mScore\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_states' is not defined"
     ]
    }
   ],
   "source": [
    "n_latest = 1000\n",
    "print(np.array(start_states)[:,:2].shape)\n",
    "plt.scatter(*np.array(np.array(start_states)[:,:2][-n_latest:]).T, c=scores[-n_latest:], cmap='RdYlGn')\n",
    "plt.colorbar(label='Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e596f509-6b4a-4ef5-b8f6-aae925b3d279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:22:23.590427Z",
     "iopub.status.busy": "2023-02-07T21:22:23.590125Z",
     "iopub.status.idle": "2023-02-07T21:29:30.269658Z",
     "shell.execute_reply": "2023-02-07T21:29:30.269067Z",
     "shell.execute_reply.started": "2023-02-07T21:22:23.590411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfsElEQVR4nO3deXRV9d3v8fc3ORkIUxgCQhgiEkAFLgoCgiKlWilX0TqhVpHeLmmtdtXqso/0Lqu3t/3jWT5Pe+vScuujfWqvFh8FFW2hyFilliEqIMioIBDDkBCGMGX63j/ODj0yZTrJyT75vNba6+z9O3uf/fuFwye//PbvnG3ujoiIhEdKoisgIiL1o+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQabLgNrOJZrbZzLaZ2eNNdR4RkdbGmmIet5mlAluA64DdwGrgLnf/NO4nExFpZZqqxz0S2Obun7t7OfAqcFMTnUtEpFWJNNHr5gK7YrZ3A6POtbOZ6eObIiKncXc7W3lTBXetzGw6MD1R5xcRCaumCu5CoHfMdq+g7BR3fx54HtTjFhGpj6Ya414N5JvZhWaWDtwJvN1E5xIRaVWapMft7pVm9hCwAEgFfu/uG5riXCIirU2TTAesdyU0VCIicoZzXZzUJydFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMo2656SZ7QCOAFVApbuPMLPOwH8BecAO4A53L21cNUVEpEY8etxfc/dh7j4i2H4cWOzu+cDiYFtEROKkKYZKbgJeCtZfAm5ugnOIiLRajQ1uB941sw/NbHpQ1t3di4L1PUD3Rp5DRERiNGqMG7jK3QvNrBuw0Mw2xT7p7m5mfrYDg6CffrbnRETk3Mz9rLla/xcyewooA+4Hxrt7kZn1AJa5+8Bajo1PJUREkoi729nKGzxUYmZtzax9zTrwDWA98DZwX7DbfcDchp5DRETO1OAet5n1A94MNiPAn9z9l2bWBXgN6AN8QXQ64IFaXks9bhGR05yrxx23oZLGUHCLiJwp7kMlIiKSGApuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhEytwW1mvzezfWa2Pqass5ktNLOtwWOnoNzM7Bkz22Zm68zs8qasvIhIa1SXHvcfgImnlT0OLHb3fGBxsA3wTSA/WKYDM+NTTRERqVFrcLv7e8CB04pvAl4K1l8Cbo4p/6NHrQCyzaxHnOoqIiI0fIy7u7sXBet7gO7Bei6wK2a/3UHZGcxsupkVmFlBA+sgItIqRRr7Au7uZuYNOO554HmAhhwvItJaNbTHvbdmCCR43BeUFwK9Y/brFZSJiEicNDS43wbuC9bvA+bGlE8NZpeMBg7FDKmIiEgcmPv5RynMbBYwHugK7AWeBN4CXgP6AF8Ad7j7ATMz4Fmis1COAd9x91rHsDVUIiJyJne3s5XXGtzNQcEtInKmcwW3PjkpIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkKk1uM3s92a2z8zWx5Q9ZWaFZrYmWCbFPDfDzLaZ2WYzu76pKi4i0lrV5WbB44Ay4I/uPjgoewooc/d/O23fS4BZwEigJ7AIGODuVbWcQ/ecFBE5TYPvOenu7wEH6niem4BX3f2ku28HthENcRERiZPGjHE/ZGbrgqGUTkFZLrArZp/dQdkZzGy6mRWYWUEj6iAi0uo0NLhnAhcBw4Ai4N/r+wLu/ry7j3D3EQ2sg4hIq9Sg4Hb3ve5e5e7VwH/wz+GQQqB3zK69gjIREYmTBgW3mfWI2fwWUDPj5G3gTjPLMLMLgXxgVeOqKCIisSK17WBms4DxQFcz2w08CYw3s2GAAzuA7wG4+wYzew34FKgEHqxtRomIiNRPrdMBm6USmg4oInKGBk8HFBGRlkXBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIytQa3mfU2s6Vm9qmZbTCzHwXlnc1soZltDR47BeVmZs+Y2TYzW2dmlzd1I0REWpO69LgrgUfd/RJgNPCgmV0CPA4sdvd8YHGwDfBNond3zwemAzPjXmsRkVas1uB29yJ3/yhYPwJsBHKBm4CXgt1eAm4O1m8C/uhRK4BsM+sR74qLiLRW9RrjNrM84DJgJdDd3YuCp/YA3YP1XGBXzGG7g7LTX2u6mRWYWUF9Ky0i0prVObjNrB0wB3jY3Q/HPufuDnh9Tuzuz7v7CHcfUZ/jRERauzoFt5mlEQ3tV9z9jaB4b80QSPC4LygvBHrHHN4rKBMRkTioy6wSA14ENrr7r2Keehu4L1i/D5gbUz41mF0yGjgUM6QiIiKNZNFRjvPsYHYV8D7wCVAdFP+U6Dj3a0Af4AvgDnc/EAT9s8BE4BjwHXc/7zi2mdVrmEVEpDVwdztbea3B3RwU3CIiZzpXcOuTkyIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQmZutwsuLeZLTWzT81sg5n9KCh/yswKzWxNsEyKOWaGmW0zs81mdn1TNkBEpLWpy82CewA93P0jM2sPfAjcDNwBlLn7v522/yXALGAk0BNYBAxw96rznEP3nBQROc257jkZqcOBRUBRsH7EzDYCuec55CbgVXc/CWw3s21EQ/wf9a61tCrt2sHQoXDsGGzfDocOJbpGiTF0KGRmwt698MUXia6NtES1BncsM8sDLgNWAmOBh8xsKlAAPOrupURDfUXMYbs5f9CLANCnD/zmN3D8OOzeDaWl0cclS+DgwWiQ790LtfyRGHqPPgoDBkBxMRQWRtu9YgVs3hz9pVZUBCdPJrqWkkh1Dm4zawfMAR5298NmNhP434AHj/8O/I96vN50YHr9qiutQVYW5OdH10eOhFtugcrKaGBt3QqHD8Pq1fDpp1BeHg34iorE1jne0tKgRw+44ILo9oQJ0V9Yhw5FA7y0FD7/HN57LxrmZWVw5Ehi6yzNp07BbWZpREP7FXd/A8Dd98Y8/x/An4PNQqB3zOG9grKvcPfngeeD45O8DyX1ZaeN7KWlRXvkvYN31uTJUFUV7ZUuWQLPPZd84Q1f/TmYQadOMGpUdNsdvve9aHBv2BD9a2XbtsTUU5pXrcFtZga8CGx091/FlPcIxr8BvgWsD9bfBv5kZr8ienEyH1gV11pLq1IzNFJVFe15Hz0K69dHe98lJfCPfyRnaMeq+Rm4R38G5eXRYaTVq6O98I0bYceOhFZRmlFdetxjgXuBT8xsTVD2U+AuMxtGdKhkB/A9AHffYGavAZ8ClcCD55tRInI69+hSXR3tUX/ySXRoYMuW6FhveXm0l3niRKJr2nRqgrq6OtrWLVtg507Yty86PFJSEh3nLitL/jF/OVOt0wGbpRIaKhFgyJCO/PSnbVi/fg/Ll0eD6vjxaHhXVia6ds3n+ecHUVKyiQ0bon9N1Izjl5UlumbS3Bo8HVCkuWRk5DNnTh6zZ89OdFUSqrT0O8yY8S+Jroa0YApuSTrp6W1JSUlt4NFGeflRqqtbURdfQkfBLUklNSWNkcPvpU/OqHPuY0QvzNQ8xpafqDrM8tW/Ze++zU1bUZFGUHBLUunTYyQX9/0mPdsPb9DxRyv2U9hrrYJbWjQFtySVKi8nPbUdYNjpk8HrICO1A1VeHv+KicSRvtZVkkrHDrmkpWY1+PjUlDS6Zl9EelrbONZKJL4U3JJEjMH9byQtpU0jXiGFPheMok1mxzjWSyS+FNySVCqrTxBJadOgYZIoI8UiVKNZJdJyKbglaURSM6j2CiIpGY16nfTUtrRv2y1OtRKJPwW3JI1Bed+gc8d+pFhag1/DzMiIdGBQv4lxrJlIfCm4hZSUFC666CJuueUW+vTp04hhhsSq9BNkRNo3uv7pqe2o8iT+IhQJPU0HbMWysrIYOXIkd999N9dffz3dunVjz549LF++nDfeeINVq1bx5Zdf0hK+z6YuTlYdblRvu0aqpZGWnkUkkkFlpe5YIC2PgrsV6tWrF9dddx333nsvw4cPp337f/ZS8/LyyMvL4/bbb2f79u28//77vPHGG6xZs4a9e/e2qBDv0L47ffqMoPDLdRw9WgJYo8e3o4xUS8cshXbtutK5U1/atu3C5i1L9FF4aREU3K1EVlYWAwcO5O677+aGG24gPz+flJSUcw4rZGRkMGjQIAYOHMh9993Hpk2bWLJkCXPmzGHjxo2UlJQ0cwvONGTQzVyWfxeHB+xmWcGvMIzoB9fjI7tDLlePeoA+Xcay7/CnbN+xghMnDsft9UUaqtUGd0ZGBu3atWPQoEFcc801nDhxgkWLFrFjxw7Kysqorq5OdBUbzczo1KkT48eP59vf/jYTJkygY8eO9RoDNjPS09MZOnQoQ4YM4YEHHmDt2rUsXLiQuXPnsmnTJsrKypq9J94lux95PUfTue1FHCj7nH37P6Nn90vjeo4TJ8qorqwmM60jF3QcwgXdLmbHzpVxPYdIQ7Sa4E5NTSUjI4MBAwZw5ZVXcuWVVzJ69Gh69epFeno67s7x48f55JNPWLZsGX/7299YuXIlR48epTJkXwYdiUTIzc3ljjvuYMqUKQwePJj09PRGX7QzMzIyMhg5ciQjRozg4Ycf5sMPP+Qvf/kL8+fPZ8uWLZSXlzdLiLfJ6kBOx0FUVp/g88L3OXky/jdcPHbiALu/XEvvbleQnXkheb1GsavwI6qqkvx2O9LiJXVwRyIR+vXrx7BhwxgzZgzjxo0jLy+Pdu3aEYlEzgiy9u3bM2bMGEaPHs0Pf/hD9u7dy5IlS1i8eDGrVq1i586dLbonnpGRwZgxY5gyZQqTJ0+ma9eupKU1/mLd2aSkpNC2bVvGjRvHmDFjeOyxxygoKGDu3LksWbKEzz77jKqqprnxkWFcfsldtIl04ujJfewsKsC9Gqeao+X7qPbG/qJ1qrwcM+Ozne9x6cD/Tqc2/ejX8xo+bDOLI2X749IOkYZKquBOTU2lV69eXHzxxYwdO5bx48fTr18/unTpQkZG3S9apaSk0L59e9q3b0///v2ZOnUq+/bt45NPPmHevHmsXLmSTZs2cfTo0SZsTd3l5uZy7bXXMm3aNIYNG1bv4ZDGikQidO3alYkTJ/L1r3+dffv2sWrVKubMmcMHH3zA9u3b43q+/n2+RrcuA0lLbUvhgYUUF38GQPmJE+z6sgCzhn4X9z+VHthNVVUlR47uZdeXBXTvMJiu7fPp2WMom7cubvTrizRGXW4WnAm8B2QE+8929yfN7ELgVaAL8CFwr7uXm1kG8EdgOFACTHH3HU1R+dTUVLp3707fvn25+uqrueaaaxgwYAC5ubm0adPw76s4XWZmJn369KFPnz5MmjSJ4uJitm3bxtKlS1m4cCFbtmyhqKioWcd5MzMzGTRo0KnedX5+fpP1rusjLS2N3NxcvvWtb3HjjTeyc+dOVqxYwezZsykoKKCwsLCRf7UYbdt3pmNmLyqqjvF54XLKy48BULh3DYV718SlHTUqq6rYvusf5OdNoHu7oVzYayyfbV+uaYKSUHXpcZ8EJrh7mZmlAcvNbD7wCPBrd3/VzP4v8F1gZvBY6u79zexO4F+BKfGobGpqKtnZ2fTs2ZMxY8Ywfvx4Bg8eTP/+/U/1qJu6p2lm5OTkkJOTw+jRo3n00UfZunUrH330EfPnz2fVqlXs2bOHY8eONcm5u3TpwlVXXcXUqVMZP3482dnZLfYDMzVDVRdeeCFTpkxh27ZtvP/++8yZM4ePPvqI4uLieod4u6yuDBlwM5mRbEqPfcGuwg+bqPb/9OW+dRSXbiWn7SVceMFVtG//n5SW7mry84qcS63B7dFuZM1tStOCxYEJwN1B+UvAU0SD+6ZgHWA28KyZmTegO5qSkkJWVhZdu3Zl7NixXH311Vx++eVcfPHFZGVlYdaw71yOl5qLdYMHD+bSSy/lnnvuYe/evaxevZply5axcOFCdu7c2ehZKmlpafTu3Zvbb7+d22+/naFDh551jL6lMjNSU1MZMGAAAwYMYOrUqWzatInFixczd+5c1q5dy+HDdZtmN6jfRNLSMqj2KnbtX8mB0p1NXHsoLz/Ktp3v0afbaDIi7eide5mCWxKqTmPcFh00/BDoDzwHfAYcdD91FWg3kBus5wK7ANy90swOER1OKa7DeUhLS6Nz586MGDHi1MyPyy+/nKysLNLS0lpsWNX8EunRowc33ngjkyZN4uTJk6xbt45ly5axdOlSVq9eTVlZWZ1nqWRlZTFq1CjuvPNObrzxRnJycohEwntZoubfrmZ64eDBg/n+97/Phg0bmDdvHh9//DFffPEFWVnn/j7tI8e+4MDBrVT5YUqObCAjI0JzXKopObiRoiMrOHSoiAMHtpKV1Zav3vgsPsyMv//975hZi/qwk7QsVp83h5llA28CTwB/cPf+QXlvYL67Dzaz9cBEd98dPPcZMMrdi097renA9GB9+NVXX80VV1zBuHHjGD58ONnZ2bRp04aUlPB/nUp1dTXHjh2jqKiIpUuXsmTJklOzVE6feWFmdOvWjUmTJnHPPfdwxRVX0K5duxb7CyteqqurOXLkCMePH69130hqOpFIJpWVJ6isar671WSkt6Oyspyq6qY9Z2lpKb/97W+ZNWtWi/igkySOu5/1P369ghvAzH4GHAf+Bbgg6FVfCTzl7teb2YJg/R9mFgH2ADnnGyoZMmSIv//++3To0CEpgro2J0+eZP/+/axdu5b58+ezYsUKNm/ezMCBA7nlllu49dZbycvLq9dMGEkuFRUVfPrppzz33HO8+eabFBfX+gerJKEGB7eZ5QAV7n7QzNoA7xK94HgfMCfm4uQ6d/+tmT0IDHH37wcXJ29x9zvOd44RI0Z4QUFBA5oVftXV1ZSUlLB7925yc3PJyclJ+t611F1FRQVr1qxh5syZvPPOOwrwVqYxwT2U6MXHVKJfA/uau//czPoRnQ7YGfgYuMfdTwbTB/8fcBlwALjT3T8/3zlac3CL1EVFRQWrVq1i5syZzJs3j9LS0kRXSZpQt27dMDP27NkTn6GSpqDgFqmdu1NRUcEHH3zAs88+y8KFC+s8G0fCIT09nUsvvZQXX3yR+++/n4KCgrMGd/IPKIskiZov/Lrmmmt4+eWXef3117nhhhvOOwtHwmPgwIE888wzLF++nGHDhp13XwW3SMiYGZmZmVx33XW8+uqrzJo1i2uvvbZFfHJW6i8zM5OpU6cyb9487r///lOfUTkfBbdISJkZbdu2ZfLkybz++uv86U9/Yty4caSmNv67WqR5jBs3jkWLFvHCCy/Qr1+/Os+qU3CLJIHs7Gxuu+023nrrLV555RWuvPJK9cBbsP79+/Pcc88xe/Zsxo4dW+9/KwW3SBLp1KkTd9xxB/Pnz+eFF15g+PDhpKenJ7paEujQoQNTpkxh0aJF/OAHPyAnJ6dBr6PgFkkyZkaHDh249957effdd3nmmWcYOnSoeuAJlJKSwrXXXsvs2bN5+eWX6du3b+NeL071EpEWpOa7czp37sz999/PokWLePrpp7n44os1Bt6MzIyePXvy85//nLfeeotrr702Lt83pOAWSXIpKSnk5OTw0EMPsXDhQn7xi1/Qv39/fUK3iaWkpDBt2jSWLVvG448/Ttu2beP2M1dwi7QSqamp5Obm8thjj7FgwQKeeOIJ8vLyEl2tpJOSksLo0aN58803efbZZ8nPz4/7XzkKbpFWJjU1lX79+vGzn/2MBQsWMGPGDPr27aseeBzk5ubyxBNP8M477zB58uQm+3CUgluklaq5ucUvf/lL/vrXv/LII4/Qs2fPRFcrlDIzM5k2bRoLFizgySefpGvXrk16vvB+K7+IxIWZMXDgQJ5++mmmTZvG7373O9544w0qKiqorKyksrLy1HpVVZVu8BAjEokwdOhQHn30UW699VbS09Ob5S8XfcmUiHxFZWUlR48epbS0lAMHDpzzsaSk5CuPhw8fprq6+qxLMurYsSOPPPIIDz30EJ06dYp7YI8YMeKcXzKlHreIfEUkEqFjx4507NjxjIuX7k51dTVVVVVUVVWd6oVXVVVx4sQJDhw4QHFxMcXFxZSUlJx6PHjw4BnLoUOHOHLkCO5+aqk5R0uWmZnJDTfcwIwZMxgyZEhC5scruEWkzmpu/HyuWRK5ublnlLk7VVVVlJeXn1oqKiooLy/n+PHjlJSUsH///q8sxcXFlJaWcujQoVMhf+jQIcrKys5y1uZzySWX8JOf/ITbbrutTl8G1VQU3CLSpMyMSCRCJBKp8ywLd6e8vJxjx459ZTl8+DB79uyhqKiIL7/8kqKiIoqKik6F+tGjR089njhxIm5tqPkg0wMPPNDoTz3Gg4JbRFocMyMjI4OMjAw6dep03n3dnePHj3P48OGvLAcPHjwV7LFLTajHLhUVFWd97czMTCZMmMCMGTMYPXp0XD71GA8toxYiIg1kZmRlZZGVlcUFF1xwqjx2rDx2/PzIkSNfuchac4F1z549X1mOHz/Oj3/8Y6ZMmZLQYZGzqTW4g3tIvgdkBPvPdvcnzewPwDXAoWDXae6+xqKt+w0wCTgWlH/UFJUXETmX2KCNXc/OziY7O/sr+9ZcdI19dHfS09Pr/B3ZzakuPe6TwAR3LzOzNGC5mc0PnnvM3Weftv83gfxgGQXMDB5FRFqkmouuYVHrrxKPqrmUmxYs55uvcxPwx+C4FUC2mfVofFVFRATq+JF3M0s1szXAPmChu68Mnvqlma0zs1+bWUZQlgvsijl8d1AmIiJxUKfgdvcqdx8G9AJGmtlgYAYwCLgC6Az8S31ObGbTzazAzAr2799fv1qLiLRi9Rp1d/eDwFJgorsXBcMhJ4H/BEYGuxUCvWMO6xWUnf5az7v7CHcf0dDb94iItEa1BreZ5ZhZdrDeBrgO2FQzbh3MIrkZWB8c8jYw1aJGA4fcvagJ6i4i0irVZVZJD+AlM0slGvSvufufzWyJmeUABqwBvh/sP4/oVMBtRKcDfifutRYRacVqDW53XwdcdpbyCefY34EHG181ERE5m5Y3s1xERM5LwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIWPunug6YGZHgM2JrkcT6QoUJ7oSTSBZ2wXJ2za1K1z6unvO2Z6INHdNzmGzu49IdCWagpkVJGPbkrVdkLxtU7uSh4ZKRERCRsEtIhIyLSW4n090BZpQsrYtWdsFyds2tStJtIiLkyIiUnctpcctIiJ1lPDgNrOJZrbZzLaZ2eOJrk99mdnvzWyfma2PKetsZgvNbGvw2CkoNzN7JmjrOjO7PHE1Pz8z621mS83sUzPbYGY/CspD3TYzyzSzVWa2NmjX/wrKLzSzlUH9/8vM0oPyjGB7W/B8XkIbUAszSzWzj83sz8F2srRrh5l9YmZrzKwgKAv1e7ExEhrcZpYKPAd8E7gEuMvMLklknRrgD8DE08oeBxa7ez6wONiGaDvzg2U6MLOZ6tgQlcCj7n4JMBp4MPi3CXvbTgIT3P2/AcOAiWY2GvhX4Nfu3h8oBb4b7P9doDQo/3WwX0v2I2BjzHaytAvga+4+LGbqX9jfiw3n7glbgCuBBTHbM4AZiaxTA9uRB6yP2d4M9AjWexCdpw7wO+Cus+3X0hdgLnBdMrUNyAI+AkYR/QBHJCg/9b4EFgBXBuuRYD9LdN3P0Z5eRANsAvBnwJKhXUEddwBdTytLmvdifZdED5XkArtitncHZWHX3d2LgvU9QPdgPZTtDf6MvgxYSRK0LRhOWAPsAxYCnwEH3b0y2CW27qfaFTx/COjSrBWuu/8D/ASoDra7kBztAnDgXTP70MymB2Whfy82VEv55GTScnc3s9BO3TGzdsAc4GF3P2xmp54La9vcvQoYZmbZwJvAoMTWqPHM7AZgn7t/aGbjE1ydpnCVuxeaWTdgoZltin0yrO/Fhkp0j7sQ6B2z3SsoC7u9ZtYDIHjcF5SHqr1mlkY0tF9x9zeC4qRoG4C7HwSWEh1CyDazmo5MbN1PtSt4viNQ0rw1rZOxwGQz2wG8SnS45DeEv10AuHth8LiP6C/bkSTRe7G+Eh3cq4H84Mp3OnAn8HaC6xQPbwP3Bev3ER0frimfGlz1Hg0civlTr0WxaNf6RWCju/8q5qlQt83McoKeNmbWhui4/UaiAX5bsNvp7app723AEg8GTlsSd5/h7r3cPY/o/6Ml7v5tQt4uADNra2bta9aBbwDrCfl7sVESPcgOTAK2EB1n/J+Jrk8D6j8LKAIqiI6lfZfoWOFiYCuwCOgc7GtEZ9F8BnwCjEh0/c/TrquIjiuuA9YEy6Swtw0YCnwctGs98LOgvB+wCtgGvA5kBOWZwfa24Pl+iW5DHdo4HvhzsrQraMPaYNlQkxNhfy82ZtEnJ0VEQibRQyUiIlJPCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQub/A78bFY+sqo3gAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the model\n",
    "import gymnasium as gym\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output\n",
    "from ddqn_torch import DoubleQAgent\n",
    "\n",
    "# Set path to the model to visualize\n",
    "model_to_animate = 'stats/m6.h5'\n",
    "\n",
    "def animate_model(name, atype='single'):\n",
    "    env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "    agent = DoubleQAgent(gamma=0.99, epsilon=0.0, lr=0.0005, mem_size=200000, batch_size=64, epsilon_end=0.01)\n",
    "    agent.load_saved_model(name)\n",
    "    state, info = env.reset(seed=12)\n",
    "    for _ in range(5):\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        while not (terminated or truncated):\n",
    "            action = agent.choose_action(state)\n",
    "            new_state, reward, terminated, truncated, info = env.step(action)\n",
    "            state = new_state\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow( env.render() )\n",
    "            plt.show()\n",
    "        state = env.reset()[0]\n",
    "    env.close()\n",
    "\n",
    "animate_model(model_to_animate, atype='double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc018ff-a067-481c-9e37-dade4167d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb Cell 6\u001b[0m line \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m         \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmean(rewards))\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m test(model, test_games\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "\u001b[1;32m/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb Cell 6\u001b[0m line \u001b[0;36mtest\u001b[0;34m(name, atype, test_games)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     rewards\u001b[39m.\u001b[39mappend(rewards)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B433a5c55736572735c63616c6c655c446f63756d656e74735c4454555c444d494149323032335c646d696169323032335c6c756e61722d6c616e646572/workspace/lunar-lander-ddqn/lunarlander-torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39;49mmean(rewards))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3474\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3472\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 3474\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39;49m_mean(a, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   3475\u001b[0m                       out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/numpy/core/_methods.py:163\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mean\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 163\u001b[0m     arr \u001b[39m=\u001b[39m asanyarray(a)\n\u001b[1;32m    165\u001b[0m     is_float16_result \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     rcount \u001b[39m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[39m=\u001b[39mkeepdims, where\u001b[39m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
